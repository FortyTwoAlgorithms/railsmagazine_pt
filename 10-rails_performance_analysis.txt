Rails: Análise de Performance
por Terry Heath

Introdução
===========

Um dos meus apectos favoritos de desenvolvimento é trabalhar com performance. A atividade, associada com profiling e ferramentas de benchmark acaba transformando-se bem em análise científica.

Usabilidade e aparência são sempre assuntos subjetivos e, na melhor das hipóteses, tem regras que mesmo assim não muito bem definidas. Ao contrário, medidas de performance são muito mais precisas.

Eu vou dar uma idéia de como abordar análise de performance e as ferramentas necessárias para as diferentes partes que compoem uma aplicação. Eu não entrei em nada muito místico porque isso iria transformar esse artigo em um livro de capa dura de 2 quilos da Barnes & Noble.


=-=-=
Terry Heath é um desenvolvedor Rails que trabalh em Austin, no Texas. Ele mantém um blog que fala algumas vezes sobre Rails em terrbear.org

=-=-=

Medida
=========

Números e não sensações
---------------------

Antes de começar a ler sobre performance e receber a tarefa de otimizar alguma coisa, eu normalmente iria otimizar algo que não "parecia" rápido. Algumas vezes isso pode ser uma boa maneira para determinar se algo precisa ser otimizado, não é uma boa medida de otimização.

Depois de trabalhar duro em otimização, você vai querer ver melhorias. Você vai querer tanto que se deixar levar pelo seu julgamento, você vai ver melhorias, mesmo se você tornou as coisas piores. Por essa razão, é importante avaliar performance numericamente através de instrumentação (profiling) e a medida de performance (benchmarking), e não sensações.

Uma outra razão para usar ferramentas e não sensações é por que elas te permitem isolar o que é realmente lento. Acontecem diversas coisas durante uma requisição via web e um exemplo é uma requisição enviada ao Apache, que é repassada para o Mongrel, que por sua vez ativa alguma ação Ruby, finalmente voltando ao cliente. Você pode ver algo no código mais interno à sua aplicação e falar "Eu sei que isso é lento, vou melhorar". Infelizmente, sem uma medida de base, você (1) não sabe o quanto sua melhoria vai de fato ajudar e (2), você não sabe ao certo se aquele código realmente precisa ser melhorado.

Números justificam tudo. Sem eles, é difícil para explicar aos seus colegas o que exatamente você tem feito durante a semana toda.


Estatística I
--------------
Eu tive a sorte de ter aulas de estatística durante a faculdade e tive a sorte de ser uma nota 10 fácil para mim. Infelizmente, eu não lembro muito além disso disso. Eu acho que você está na mesma situação.

=-=-=-=-=-=-
Para aguçar sua memória...

Média: x' =  1/n Sum(i=1, n, xi)
Desvio padrão: sigma = Sqrt(E((X-E(X)))^2)

(nota ao revisor: acho que vale a pena aprofundar os conhecimentos aqui, acho que nem todo mundo lembra o que é uma variável aleatória...)

=--=-=-=-=-=-

Embora eu acho que isso é ensinado como um axioma ou algo assim sobre tamanho de amostras, em conversas casuais já ouvi esse conceito ser referido como "lei dos pequenos números". Essensialmente, se você não tem amostras suficientes, você não pode ter certeza sobre o que você está medindo. Você talvez esteja medindo o tempo do garbage collector do Ruby quando você quer de fato ver quanto tempo um match em expressão regular está tomando. Isso não só iria levar a resultados falsos como pode desviar a sua atenção nos esforços de otimização. Resumindo, quanto mais executar os testes, melhor.

Enquanto se estiver tomando medidas estatísticas, é importante reduzir fatores que podem prejudicar a análise. Qualquer coisa que possa interferir com os números que você está coletando pode afetar seus dados. Se você executar seus benchmarks localmente, feche outras aplicações em execução. Reforçando, é difícil saber se o que você está medindo é realmente o match de expressão regular se seu iTunes está passando o Senhor dos Anéis e jogando Tower Defense no Firefox. Talvez colocar uma torre de água no jogo consuma alguma CPU, influenciando no processo Ruby. O timer não irá saber e nem você.

Se você está testando a vazão do servidor, garanta que você está testando o mais próximo da máquina que puder. Se você tem um servidor espelho que fica a alguns metros de você, melhor, pois você não está medindo velocidade de roteadores e nem buracos negros na internet.

Por último, quando apresentar suas medidas, calcule o desvio padrão e a média. Isso é extremamente importante. O desvio padrão indica o quanto as medidas desviam da média. Um desvio padrão deve cobrir cerca de 70% dos casos e um segundo desvio padrão deve cobrir 90% dos casos. Embora não haja nenhuma implementação embutida no Ruby para cálculo de desvio padrão, eu providenciei um em [0].

Se você tem uma requisição que está tomando metade de um segundo, você pode pensar "que bom, nossa aplicação é tão rápida!", mas se você comparar essa informação com o desvio padrão que digamos seja 12 segundos, você pode ter certeza que muitas pessoas estão esperando muito mais que meio segundo. Esse comportamento pode revelar que algum código de backend está travando ou um "race condition" que apenas uma média não iria mostrar.

Rails
-----------

É importante notar que todas as três áreas mencionadas (backend, frontend e configuração de servidores) podem afetar signifcamente a performance. Por sorte, tanto o backend e frontend Rails podem ser diagnosticado e instrumentado individualmente, então não temos que empurrar dominós nos nossos ajustes.

Configuração e ajuste de servidores, por exemplo o número de instâncias mongrel para executar em um servidor, não podem ser feitos por si só. Como o processamento de backend pode aumentar tanto o consumo de memória quanto o tempo que uma instância mongrel demora para desbloquear o processo, as coisas do lado Rails precisam ser ajustadas antes.

Onde procurar?
-------------

A primeira tarefa é descobrir o que precisa ser otimizado. Um bom lugar para começar são os logs de produção, já que eles irão mostrar onde as pessoas vão e quanto tempo o servidor toma para responder.

Existe uma ferramenta chamada PL Analyzer [1], parte da suite Rails Analyzer, mas não funciona "out-of-the-box" no OSX, no qual eu trabalho. Ele também trabalha com um conjunto separado de dados, então eu uso um programa que fiz há um tempo atrás chamado logpwnr [2] para converter os dados.

O logpwnr irá gerar medidas completas de todas as actions usadas em sua aplicação. Se você tem vários servidores de produção, você precisará concatenar todos os logs antes de transformá-los com o logpwnr. Rode ele assim:

./logpwnr.rb production.log > output.csv

Assim você irá ter um CSV que você pode importar em qualquer planilha.


tabela:

name -> nome
hits -> vis.
action avg -> méd. action
action avg stddev -> méd. desvp action
render avg -> méd. render
render avg stddev -> méd. desvp render
db avg -> méd. bd
db avg stddev -> méd. desvp bd

Aqui podemos começar a procurar pelo que é mais usado e depois ver qual das actions pode ser uma candidata a ser otimizada, usando o tempo total de requisição (não exibido na tabela, mas é a soma das médias de bd, action e render). Tente avaliar os números no contexto do uso. Pode haver actions terrivelmente lentas em sua applicação, mas usadas apenas 5 vezes em alguns meses. Otimizar actions raramente usadas não valem o esforço até que todas as actions populares estiverem mais velozes.

Para baixo na toca do coelho

(nota ao revisor: eu não tenho Alice no País das maravilhas em portugues, 
então usei o título do capítulo mais comum pelo Google, se você encontrar um nome melhor para o capítulo,
fique a vontade)
------------------------------

Uma vez encontrada a action que parece boa para ser otimizada, podemos pensar em como atacar o problema usando o RubyProf. O Rubyprof é parcialmente mantido por Charlie Savage [3], que fez um dos melhores guias rápidos para acelerar Rails[4]. Ele também fez um guia fantástico de instalação do RubyProf [5].

Um problema é que se você está usando Rails <= 1.1.6, você terá que fazer aliases de métodos por conta própria ou especificar alias_method_chain no plugin. Eu prefiro o último e apenas coloquei essee trecho do código do Rails [6] no topo do plugin.

Novamente, é importante mensurar novamente todas as alterações que você fez para justificar seus refactorings e como direcionar seus esforços de otimização, mas se for para levar apenas algumas coisas de conhecimento para si, Charlie disponibiliza as seguintes guidelines para performance de backend:

* Não use ActiveRecord#attributes - O ActiveRecord já clona todos os atributos associados com o objeto toda vez que ele é acessado;
* Acerte seus ActiveRecord :includes - Includes muito agressivos podem gerar joins desnecessários no banco de dados, enquanto a falta deles pode resultar em um aumento no número de queries no banco.
* Não verifique hora e data de templates (cache_template_loading = true)
(nota ao revisor: eu infelizmente não entendi esse ponto!!)
* Não use url_for - buscar pela tabela de rotas todas as vezes é lento
* Não deixe o Rails interpretar data e hora - A classe Date do Ruby (e os monkeypatches do Rails em cima dele) é dolorosamente lenta.
* Não transforme chaves em símbolos (local_assigns_support_string_keys = true)

E algumas sugestões minhas:
* Sempre use if's em cláusulas de debug, exemplo "logger.debug (em Controller#new) if logger.debug?" - isso é importante para evitar chamadas desnecessárias ao método to_s e também faz "curto circuito" em outros métodos em um ambiente de produção; não comente as cláusulas logger, já que elas são úteis para, você sabe, debuggar.

* Evite helpers inúteis do Rails (a tag HTML <img> é mais rápido e tão fácil quanto o helper image_tag)
* Evite cópias inúteis de objetos (como gsub) quando você pode usar alternativas que alteram o próprio objeto (gsub!)


Otimizaçã de frontend
=-=-=-=-=-=-=-=-=-=-

Uma ferramenta fantástica para determinar tempo de carga de uma página web é o YSlow [7], uma ferramenta da Yahoo como um addon ao Firebug [8]. YSlow pontua sua página através de diversos critérios e faz recomendações de como melhorar seu site.

Um site extremamente veloz no backend com uma pontuação terrível no YSlow vai ser geralmente visto como pesado pelos usuários.

Uma das coisas mais fáceis para ser feitas é comprimir seus arquivos Javascript e CSS. Se você usa uma ferramenta como o asset packager [9], você pode ter seus javascripts e css's em ambiente de produção concatenados e "minificados", necessitando apenas 2 downloads pelos seus usuários. Esse é um grande ganho porquê você não só diminui consumo de banda como o número de downloads necessários para ver uma página. Muitos browsers vem preparados para fazer apenas 2 downloads de arquivos por vez de um servidor, então menos downloads é sempre bom.

O YSlow em sua essência olha para elementos da página que travam o download de páginas e maneiras de como acelerar o tempo de downloads. Para esse fim, alguns ajustes no Apache podem render bons frutos.

Ajustes do Apache
-----------------

A maioria dos browsers populares aceitam conteúdo compactados com gzip. Então zipe tudo usando o mod_deflate [10] do Apache. Além disso, arquivos estáticos podem ter data de expiração bem no futuro. Você pode simplesmente colocar:

ExpiresDefault "access plus 10 years" 

em sua configuração do Apache e então todos os seus arquivos estáticos vão conter esse cabeçalho HTTP. No trabalho, encontramos um problema com o cabeçalho Expires-Default e o IE7 que até requisições processadas pelo Mongrel estavam sendo armazenadas em cache, então precisamos deixar as coisas mais claras, tirando a cláusula ExpiresDefault com:

ExpiresByType image/gif "access 10 years"
ExpiresByType image/jpg "access 10 years"
ExpiresByType image/png "access 10 years"
ExpiresByType text/css "access 10 years"
ExpiresByType text/javascript "access 10 years"

Um perigo com essa abordagem é que caching pode causar problemas se você atualizar suas imagens ou CSS ou javascripts. O Asset packager resolve isso com seus CSSs e javascripts e você pode usar a mesma técnica com suas imagens - mudar o nome do arquivo cada vez que os arquivos forem alterados. Um número de revisão SVN ou Git resolve muito bem.

Por fim, a configuração de ETags pode ser ajustada no Apache. Mais especificamente, pode ser desativado. Isso é bem importante quando seu site se torna grande o suficiente para tomar diversos servidores de conteúdo estático. O mecanismo de hashing padrão de ETags é dependente da máquina, então arquivos em diferentes servidores irão ter ETags diferentes. Isso gera invalidação desnecessária de cache e invalida o processamento feito pelo servidor para gerar o ETag. Para desligá-lo no Apache, basta:

FileETag none

no seu httpd.conf

Na ponta do Rails, entretanto, ETags são muito mais úteis. O Rails tem um mecanismo embutido para ETags que é confiável e consistente em diversas máquinas e no Rails 2.2 o código foi simplificado. Você pode definir condições para expiração e fazer uma action inteiramente assim:

if stale?(:last_modified => @user.updated_at, :etag => @user)
	<código>
end
	
E o <código> não será executado até que a data é alterada ou o ETag o indique.

Depois de fazer essas mudanças, trabalhe com o YSlow e veja o que consegue melhorar. O YSlow tem links excelentes que explica tanto os problemas de sua página e também de como resolvê-los.


Servidor/Ajustes no HTTP
-=-=-=-=-=-=-=-=-=-=-=-=-=

Parece que o Phusion Passenger não tem o mesmo problema com ajustes como o Mongrel, mas se você precisar fazer proxy com múltiplos Apaches ou experimentar como se comporta seu servidor em alto tráfego, essa seção será bem útil.

Eu não sei como a maioria das pessoas configuram várias máquinas com Mongrels, mas descobrimos recentemente em uma das nossas aplicações, que nós havíamos configurado mal. Tínhamos algo do tipo:

Ignore o fato de que há apenas duas setas (deveriam ser seis) saindo das caixas do Apache; isso é preguiça minha. O problema aqui é que nós tínhamos uma instância Apache delegando para outras 4 instâncias que por sua vez passava a requisição para o Mongrel ou servia conteúdo estático.

A análise com httperf[12] (daqui a poucos parágrafos!) mostrou que, para requisições pequenas, a diferença foi despresível, mas quando o número de requisições por segundo começou a acumular, Apaches que delegam para outros Apaches desnecessariamente logo se tornaram gargalo. Fazendo proxy diretamente do Apache balanceador de carga para instâncias Mongrel mostrou uma melhoria de 25% em alto tráfego (500 reqs/s por 10 segundos).

Como um lembrete rápido, o Mongrel executava como uma thread sincronizada até o Rails 2.2. Isso significa que, para o Rails, uma instância Mongrel só poderia responder 1 única requisição por vez e quando essa instância está processando a requisição, ela acaba bloqueando todas as outras requisições chegando a ela. Isso leva a uma solução óbvia de escalabilidade (até um certo ponto): mais Mongrels!

Mas mesmo antes de pensar no número correto de Mongrels por máquina, você tem que garantir que você não está usando o Mongrel para coisas que ele não deveria. O Mongrel não é nem de perto tão bom quanto o Apache para servir arquivos estáticos, então tenha certeza que sua pasta public esteja sendo servida diretamente pelo Apache, anterior a qualquer intervenção. Coloque isso no seu arquivo vhost (assumindo que todas as suas regras de Rewrite estejam correntas):

<Directory "/your/apps/public/directory">
	Option FollowSymLinks
	AllowOverride None
	Order allow,deny
	Allow from all
</Directory>

# Rewrite index parar checar por arquivos estáticos
RewriteRule ^/$ /index.html [QSA]

# Rewrite para checar por páginas em cache do Rails
RewriteRule ^([^.]+)$ $1.html [QSA]

RewriteRule ".*(images|stylesheets|javascripts)/?(.*)" "$0" [L]

E então depois de reiniciar o Apache, seus arquivos estáticos vão ser servidos pelo Apache. Agora é hora de ajustar instâncias Mongrel.


Conheça o httperf
-=-=-=-=-=-=-=-=-=-

Então, enquanto muitas dessas coisas devem ser feitas com cuidado ou em período de manutenção, esse último teste parece pode ser feito durante o dia. Isso seria muito errado. Se você conseguir marretar bem seu servidor, você pode derrubar tudo (e falo por experiência quando usei inocentemente o httperf o servidor de produção há uns anos atrás). Faça testes em períodos de pouco tráfego.

Essa é basicamente uma recaptulação de um post em um mailing list [13] incrivelmente esclarecedor do Zed Shaw (de fama do Mongrel e "Rails is a Ghetto").

Primeiramente, encontre uma máquina perto (tanto na rede quanto em proximidade) do servidor que você quer testar, mas não a mesma máquina (testar a interface loopback não ajudam muito).

O próximo passo, você vai querer testar arquivos estáticos naquela máquina. A boa notícia é que se você seguiu por esse guia, todos os seus arquivos estáticos estão sendo servidos pelo Apache. Isso te dá um ponto de partida de melhor caso, no qual você pode testar seus Mongrels.

Comece executando um comando tipo:
httperf --hog --server=<seu servidor> --uri=<seu recurso, como /happy.jpg> --num-conns

Você terá alguma saída do programa mas o que você deve prestar atenção antes é a duração do teste. O Zed recomenda 10 segundos, que funciona bem para um caso de teste abrangente contra um servidor de arquivos estáticos e muitas requisições. Em um servidor "parrudo" da produção que temos, tive algo assim com num-conns de 1200.

Depois de encontrar o número mágico, tente executar apenas uma requisição (--num-conns 1) contra uma action (--url <action>) em sua aplicação Rails que possa dar uma idéia de como sua aplicação funciona. Você não quereria executar na action mais lenta e executar conteúdo estático não vai ajudar em nada. Tenha certeza de encontrar uma página que não precise de login, já que isso irá resultar em redirects inúteis.

Se apenas uma requisição foi muito lenta, então você provavelmente tem uma configuração incorreta para os Mongrels ou alguma coisa está bem errada. Essa execução deveria ser pelo menos tão rápida quanto as coisas em desenvolvimento localmente e provavelmente muito mais rápido. Se sua simples requisição Rails está mais rápida que uma requisição estática, então o conteúdo estático provavelmente não está estático - o Apache é mais veloz que o Mongrel, isso é fato. 

Depois que uma requisição simples pareca bem, tente executar com --num-conns igual ao seu número mágico encontrado anteriormente, com 10 segundos de execução, para o seu servidor de conteúdo estático e coloque --rate para num-conns/10. Isso idealmente irá te dar testes com 10 segundos de duração, apesar de que na prática é um pouco mais que isso. Então execute novamente. É importante que os caches sejam feitos e que todos os Mongrels são levantados antes de executar um teste de performance. Nunca use números de um teste executado pela primeira vez.

Agora tente adicionar uma instância do Mongrel, reinicie as coisas e execute o teste novamente. Se você encontrou melhorias no tempo geral to teste, você está progredindo.

Existe um número ideal de instâncias Mongrel em um processador e você irá encontrá-lo facilmente. Aumentando o número de Mongrels por um. Assim que você alcançar o ápice, você deverá então encontrar uma queda drástica de performance. Eu já vi essa queda ser algo próximo a 25%, apenas adicionando um Mongrel. Quando você encontrar esse número, reduza um Mongrel e você tem o número ideal para sua aplicação e servidor atual.

Se você seguir os links, você provavelmente irá ver (tanto quantitativamente quanto qualitativamente) ganhos bem notáveis de performance.
